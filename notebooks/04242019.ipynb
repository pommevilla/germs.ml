{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GERMS-ML\n",
    "\n",
    "## Meeting #5: Groundwater Revisited\n",
    "\n",
    "This week will be more coding focused. We're going to several different classifiers to the MNIST dataset and Jae's dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Groundwater dataset\n",
    "\n",
    "Let's revisit the groundwater data set. We didn't actually make it predictions last time. We'll skip through the preprocessing and move to predictions.\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "This time, we'll only read in the 3-month-adjusted dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "gw = pd.read_excel(\"../data/gw.xlsx\", sheet_name = \"Raw_Sorted_3month\",\n",
    "                  skiprows = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the non-numeric data for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw.drop([\"Internal Wel lID\", \"Date\"], axis = 1,\n",
    "                                   inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how much data is missing in each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NO2</th>\n",
       "      <td>22.994652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ferrous</th>\n",
       "      <td>16.042781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tDCE</th>\n",
       "      <td>4.278075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chloride</th>\n",
       "      <td>3.208556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NO3</th>\n",
       "      <td>3.208556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Redox</th>\n",
       "      <td>2.139037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DO</th>\n",
       "      <td>0.534759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>0.534759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Methane</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCE</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dhc16S</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DP (3month later)</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethene</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cDCE</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sulfate</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCE</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   percent_missing\n",
       "NO2                      22.994652\n",
       "Ferrous                  16.042781\n",
       "tDCE                      4.278075\n",
       "Chloride                  3.208556\n",
       "NO3                       3.208556\n",
       "Redox                     2.139037\n",
       "DO                        0.534759\n",
       "pH                        0.534759\n",
       "Methane                   0.000000\n",
       "TCE                       0.000000\n",
       "Dhc16S                    0.000000\n",
       "DP (3month later)         0.000000\n",
       "Ethene                    0.000000\n",
       "VC                        0.000000\n",
       "cDCE                      0.000000\n",
       "Sulfate                   0.000000\n",
       "TOC                       0.000000\n",
       "PCE                       0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "from gml_utils.preprocessing import get_missing_percentage\n",
    "missing_percentage = get_missing_percentage(gw)\n",
    "missing_percentage.sort_values(by = \"percent_missing\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look too bad - most of the data is there, and there are enough values in the columns with higher missing percentages for us to impute missing values. \n",
    "\n",
    "Before we do get started with data preprocessing, let's split the data into a testing and training set. First, we separate our data into attributes and target sets. Our target is `DP (3month later)`, and the remaining columns will be our attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_targets = gw[\"DP (3month later)\"]\n",
    "gw_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_attributes = gw.drop(columns = \"DP (3month later)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into testing and training sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "gw_x_train, gw_x_test, gw_y_train, gw_y_test = train_test_split(\n",
    "    gw_attributes, gw_targets, test_size = 0.2, random_state = 489\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, before we did any training on the dataset, we did imputation followed by standardization. Let's make a pipeline to do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "gw_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = \"median\")),\n",
    "    (\"standardization\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we need to do is call `fit_transform` on our training data and it will be preprocessed. Let's look at the values before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCE</th>\n",
       "      <th>TCE</th>\n",
       "      <th>cDCE</th>\n",
       "      <th>tDCE</th>\n",
       "      <th>VC</th>\n",
       "      <th>Ethene</th>\n",
       "      <th>Dhc16S</th>\n",
       "      <th>Methane</th>\n",
       "      <th>pH</th>\n",
       "      <th>DO</th>\n",
       "      <th>Redox</th>\n",
       "      <th>NO3</th>\n",
       "      <th>NO2</th>\n",
       "      <th>Ferrous</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>TOC</th>\n",
       "      <th>Chloride</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1888.068389</td>\n",
       "      <td>304.903785</td>\n",
       "      <td>1207.266577</td>\n",
       "      <td>64.846783</td>\n",
       "      <td>1218.371409</td>\n",
       "      <td>472.142311</td>\n",
       "      <td>1.087982e+06</td>\n",
       "      <td>3484.081101</td>\n",
       "      <td>6.759732</td>\n",
       "      <td>1.926242</td>\n",
       "      <td>-68.503673</td>\n",
       "      <td>2.859741</td>\n",
       "      <td>0.589400</td>\n",
       "      <td>4.794603</td>\n",
       "      <td>46.659430</td>\n",
       "      <td>494.163490</td>\n",
       "      <td>65.279371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12679.776643</td>\n",
       "      <td>1204.025864</td>\n",
       "      <td>4626.077043</td>\n",
       "      <td>262.590985</td>\n",
       "      <td>4263.934981</td>\n",
       "      <td>2097.181516</td>\n",
       "      <td>5.894971e+06</td>\n",
       "      <td>5910.758338</td>\n",
       "      <td>0.563965</td>\n",
       "      <td>4.359515</td>\n",
       "      <td>100.070519</td>\n",
       "      <td>6.866195</td>\n",
       "      <td>1.113918</td>\n",
       "      <td>16.665491</td>\n",
       "      <td>87.338674</td>\n",
       "      <td>1457.250963</td>\n",
       "      <td>81.922656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>5.610000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-445.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>6.770000e+01</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>-116.350000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.650000</td>\n",
       "      <td>22.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.700000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.600000</td>\n",
       "      <td>4.460000</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>613.000000</td>\n",
       "      <td>6.670000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>-78.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>32.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.700000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>99.200000</td>\n",
       "      <td>2.800000e+05</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>6.860000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>-25.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.192500</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>59.300000</td>\n",
       "      <td>72.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>108700.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>51000.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>38000.000000</td>\n",
       "      <td>19200.000000</td>\n",
       "      <td>5.500000e+07</td>\n",
       "      <td>34600.000000</td>\n",
       "      <td>9.160000</td>\n",
       "      <td>47.100000</td>\n",
       "      <td>226.800000</td>\n",
       "      <td>63.900000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>8300.000000</td>\n",
       "      <td>460.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PCE           TCE         cDCE         tDCE             VC  \\\n",
       "count     149.000000    149.000000    149.000000   143.000000    149.000000   \n",
       "mean     1888.068389    304.903785   1207.266577    64.846783   1218.371409   \n",
       "std     12679.776643   1204.025864   4626.077043   262.590985   4263.934981   \n",
       "min         0.000000      0.250000      0.350000     0.000000      0.340000   \n",
       "25%         0.550000      1.000000     14.900000     0.410000      2.200000   \n",
       "50%         1.700000     10.000000    110.000000     1.000000     64.600000   \n",
       "75%         9.700000     74.000000    800.000000     6.500000    310.000000   \n",
       "max    108700.000000  10000.000000  51000.000000  2100.000000  38000.000000   \n",
       "\n",
       "             Ethene        Dhc16S       Methane         pH           DO  \\\n",
       "count    149.000000  1.490000e+02    149.000000  149.000000  149.000000   \n",
       "mean     472.142311  1.087982e+06   3484.081101    6.759732    1.926242   \n",
       "std     2097.181516  5.894971e+06   5910.758338    0.563965    4.359515   \n",
       "min        0.010000  1.000000e+01      0.013000    5.610000    0.020000   \n",
       "25%        0.500000  6.770000e+01     38.000000    6.500000    0.340000   \n",
       "50%        4.460000  2.000000e+04    613.000000    6.670000    0.610000   \n",
       "75%       99.200000  2.800000e+05   4500.000000    6.860000    1.880000   \n",
       "max    19200.000000  5.500000e+07  34600.000000    9.160000   47.100000   \n",
       "\n",
       "            Redox         NO3         NO2     Ferrous     Sulfate  \\\n",
       "count  147.000000  143.000000  115.000000  126.000000  149.000000   \n",
       "mean   -68.503673    2.859741    0.589400    4.794603   46.659430   \n",
       "std    100.070519    6.866195    1.113918   16.665491   87.338674   \n",
       "min   -445.000000    0.040000    0.100000    0.000000    0.000000   \n",
       "25%   -116.350000    0.500000    0.500000    0.042500    5.000000   \n",
       "50%    -78.200000    0.500000    0.500000    0.390000   29.000000   \n",
       "75%    -25.500000    2.000000    0.500000    1.192500   56.500000   \n",
       "max    226.800000   63.900000   12.000000  100.000000  666.000000   \n",
       "\n",
       "               TOC    Chloride  \n",
       "count   149.000000  143.000000  \n",
       "mean    494.163490   65.279371  \n",
       "std    1457.250963   81.922656  \n",
       "min       0.800000    2.400000  \n",
       "25%       6.650000   22.800000  \n",
       "50%      14.200000   32.800000  \n",
       "75%      59.300000   72.100000  \n",
       "max    8300.000000  460.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and compare them to the values after our preprocessing pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_x_train = pd.DataFrame(gw_pipeline.fit_transform(gw_x_train),\n",
    "                          columns = gw_x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCE</th>\n",
       "      <th>TCE</th>\n",
       "      <th>cDCE</th>\n",
       "      <th>tDCE</th>\n",
       "      <th>VC</th>\n",
       "      <th>Ethene</th>\n",
       "      <th>Dhc16S</th>\n",
       "      <th>Methane</th>\n",
       "      <th>pH</th>\n",
       "      <th>DO</th>\n",
       "      <th>Redox</th>\n",
       "      <th>NO3</th>\n",
       "      <th>NO2</th>\n",
       "      <th>Ferrous</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>TOC</th>\n",
       "      <th>Chloride</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "      <td>1.490000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.862790e-18</td>\n",
       "      <td>2.235348e-18</td>\n",
       "      <td>7.078603e-18</td>\n",
       "      <td>7.451161e-18</td>\n",
       "      <td>-1.266697e-17</td>\n",
       "      <td>6.706045e-18</td>\n",
       "      <td>6.501138e-17</td>\n",
       "      <td>-1.918674e-17</td>\n",
       "      <td>1.473467e-15</td>\n",
       "      <td>4.060883e-17</td>\n",
       "      <td>1.918674e-16</td>\n",
       "      <td>5.960929e-18</td>\n",
       "      <td>-9.742393e-17</td>\n",
       "      <td>3.148116e-17</td>\n",
       "      <td>-9.947300e-17</td>\n",
       "      <td>-1.415721e-17</td>\n",
       "      <td>-4.470697e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "      <td>1.003373e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.494061e-01</td>\n",
       "      <td>-2.538827e-01</td>\n",
       "      <td>-2.617741e-01</td>\n",
       "      <td>-2.426433e-01</td>\n",
       "      <td>-2.866224e-01</td>\n",
       "      <td>-2.258863e-01</td>\n",
       "      <td>-1.851817e-01</td>\n",
       "      <td>-5.914332e-01</td>\n",
       "      <td>-2.045533e+00</td>\n",
       "      <td>-4.387347e-01</td>\n",
       "      <td>-3.799213e+00</td>\n",
       "      <td>-4.055242e-01</td>\n",
       "      <td>-4.809930e-01</td>\n",
       "      <td>-2.681085e-01</td>\n",
       "      <td>-5.360374e-01</td>\n",
       "      <td>-3.396995e-01</td>\n",
       "      <td>-7.674406e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.493626e-01</td>\n",
       "      <td>-2.532576e-01</td>\n",
       "      <td>-2.586183e-01</td>\n",
       "      <td>-2.410458e-01</td>\n",
       "      <td>-2.861848e-01</td>\n",
       "      <td>-2.256519e-01</td>\n",
       "      <td>-1.851719e-01</td>\n",
       "      <td>-5.849848e-01</td>\n",
       "      <td>-4.620987e-01</td>\n",
       "      <td>-3.650845e-01</td>\n",
       "      <td>-4.811642e-01</td>\n",
       "      <td>-3.370617e-01</td>\n",
       "      <td>-7.076443e-02</td>\n",
       "      <td>-2.641990e-01</td>\n",
       "      <td>-4.785959e-01</td>\n",
       "      <td>-3.356716e-01</td>\n",
       "      <td>-5.106776e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.492716e-01</td>\n",
       "      <td>-2.457575e-01</td>\n",
       "      <td>-2.379916e-01</td>\n",
       "      <td>-2.387470e-01</td>\n",
       "      <td>-2.715010e-01</td>\n",
       "      <td>-2.237573e-01</td>\n",
       "      <td>-1.817793e-01</td>\n",
       "      <td>-4.873764e-01</td>\n",
       "      <td>-1.596449e-01</td>\n",
       "      <td>-3.029421e-01</td>\n",
       "      <td>-9.656535e-02</td>\n",
       "      <td>-3.370617e-01</td>\n",
       "      <td>-7.076443e-02</td>\n",
       "      <td>-2.426966e-01</td>\n",
       "      <td>-2.028768e-01</td>\n",
       "      <td>-3.304731e-01</td>\n",
       "      <td>-3.885282e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.486385e-01</td>\n",
       "      <td>-1.924232e-01</td>\n",
       "      <td>-8.833406e-02</td>\n",
       "      <td>-2.188761e-01</td>\n",
       "      <td>-2.137544e-01</td>\n",
       "      <td>-1.784300e-01</td>\n",
       "      <td>-1.375251e-01</td>\n",
       "      <td>1.724559e-01</td>\n",
       "      <td>1.783916e-01</td>\n",
       "      <td>-1.064283e-02</td>\n",
       "      <td>4.303654e-01</td>\n",
       "      <td>-1.733469e-01</td>\n",
       "      <td>-7.076443e-02</td>\n",
       "      <td>-2.009950e-01</td>\n",
       "      <td>1.130514e-01</td>\n",
       "      <td>-2.994200e-01</td>\n",
       "      <td>1.000693e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.452213e+00</td>\n",
       "      <td>8.079390e+00</td>\n",
       "      <td>1.079979e+01</td>\n",
       "      <td>7.939527e+00</td>\n",
       "      <td>8.655311e+00</td>\n",
       "      <td>8.960131e+00</td>\n",
       "      <td>9.176270e+00</td>\n",
       "      <td>5.282040e+00</td>\n",
       "      <td>4.270413e+00</td>\n",
       "      <td>1.039705e+01</td>\n",
       "      <td>2.982244e+00</td>\n",
       "      <td>9.098863e+00</td>\n",
       "      <td>1.172331e+01</td>\n",
       "      <td>6.247765e+00</td>\n",
       "      <td>7.115169e+00</td>\n",
       "      <td>5.374615e+00</td>\n",
       "      <td>4.936188e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PCE           TCE         cDCE          tDCE             VC  \\\n",
       "count  1.490000e+02  1.490000e+02  1.490000e+02  1.490000e+02  1.490000e+02   \n",
       "mean   1.862790e-18  2.235348e-18  7.078603e-18  7.451161e-18 -1.266697e-17   \n",
       "std    1.003373e+00  1.003373e+00  1.003373e+00  1.003373e+00  1.003373e+00   \n",
       "min   -1.494061e-01 -2.538827e-01 -2.617741e-01 -2.426433e-01 -2.866224e-01   \n",
       "25%   -1.493626e-01 -2.532576e-01 -2.586183e-01 -2.410458e-01 -2.861848e-01   \n",
       "50%   -1.492716e-01 -2.457575e-01 -2.379916e-01 -2.387470e-01 -2.715010e-01   \n",
       "75%   -1.486385e-01 -1.924232e-01 -8.833406e-02 -2.188761e-01 -2.137544e-01   \n",
       "max    8.452213e+00  8.079390e+00  1.079979e+01  7.939527e+00  8.655311e+00   \n",
       "\n",
       "             Ethene        Dhc16S       Methane           pH             DO  \\\n",
       "count  1.490000e+02  1.490000e+02  1.490000e+02  1.490000e+02  1.490000e+02   \n",
       "mean   6.706045e-18  6.501138e-17 -1.918674e-17  1.473467e-15  4.060883e-17   \n",
       "std    1.003373e+00  1.003373e+00  1.003373e+00  1.003373e+00  1.003373e+00   \n",
       "min   -2.258863e-01 -1.851817e-01 -5.914332e-01 -2.045533e+00 -4.387347e-01   \n",
       "25%   -2.256519e-01 -1.851719e-01 -5.849848e-01 -4.620987e-01 -3.650845e-01   \n",
       "50%   -2.237573e-01 -1.817793e-01 -4.873764e-01 -1.596449e-01 -3.029421e-01   \n",
       "75%   -1.784300e-01 -1.375251e-01  1.724559e-01  1.783916e-01 -1.064283e-02   \n",
       "max    8.960131e+00  9.176270e+00  5.282040e+00  4.270413e+00  1.039705e+01   \n",
       "\n",
       "              Redox           NO3           NO2       Ferrous       Sulfate  \\\n",
       "count  1.490000e+02  1.490000e+02  1.490000e+02  1.490000e+02  1.490000e+02   \n",
       "mean   1.918674e-16  5.960929e-18 -9.742393e-17  3.148116e-17 -9.947300e-17   \n",
       "std    1.003373e+00  1.003373e+00  1.003373e+00  1.003373e+00  1.003373e+00   \n",
       "min   -3.799213e+00 -4.055242e-01 -4.809930e-01 -2.681085e-01 -5.360374e-01   \n",
       "25%   -4.811642e-01 -3.370617e-01 -7.076443e-02 -2.641990e-01 -4.785959e-01   \n",
       "50%   -9.656535e-02 -3.370617e-01 -7.076443e-02 -2.426966e-01 -2.028768e-01   \n",
       "75%    4.303654e-01 -1.733469e-01 -7.076443e-02 -2.009950e-01  1.130514e-01   \n",
       "max    2.982244e+00  9.098863e+00  1.172331e+01  6.247765e+00  7.115169e+00   \n",
       "\n",
       "                TOC      Chloride  \n",
       "count  1.490000e+02  1.490000e+02  \n",
       "mean  -1.415721e-17 -4.470697e-18  \n",
       "std    1.003373e+00  1.003373e+00  \n",
       "min   -3.396995e-01 -7.674406e-01  \n",
       "25%   -3.356716e-01 -5.106776e-01  \n",
       "50%   -3.304731e-01 -3.885282e-01  \n",
       "75%   -2.994200e-01  1.000693e-01  \n",
       "max    5.374615e+00  4.936188e+00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_x_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we might as well preprocess the testing attributes while we're at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_x_test = pd.DataFrame(gw_pipeline.fit_transform(gw_x_test),\n",
    "                        columns = gw_x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to train some models.\n",
    "\n",
    "#### Q1\n",
    "\n",
    "1. We dropped Well ID and Date as unimportant. What potential problems are there by doing this?\n",
    "\n",
    "#### Random Forest Classifier\n",
    "\n",
    "We're going to skip right to parameter tuning. You can read about Random Forests [here](https://en.wikipedia.org/wiki/Random_forest). In short, a random forest classifier is a collection of resampled decision trees (or a \"bootstrap aggregation\" or \"bagged\"). The idea is that while an individual tree may not be very accurate in terms of predictive powers, a collection of many trees tends to be more accurate when we take the majority vote as the prediction.\n",
    "\n",
    "The parameters we'll be tuning are:\n",
    "\n",
    "* `n_estimators` - the number of trees in the forest\n",
    "* `max_features` - the number of features to consider when looking for the best split\n",
    "\n",
    "You can read more about these hyperparameters (and all the other ones) at the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'n_estimators': [50, 100, 150, 200], 'max_features': ['sqrt', 'log2']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "gw_rf = RandomForestClassifier()\n",
    "\n",
    "rf_param_grid = [\n",
    "    {\n",
    "        'n_estimators': [50 * (i + 1) for i in range(4)],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "]\n",
    "\n",
    "rf_grid_search = GridSearchCV(gw_rf, rf_param_grid, cv = 5)\n",
    "rf_grid_search.fit(gw_x_train, gw_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785234899328859"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'log2', 'n_estimators': 150}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the performance on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_rf = rf_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gml_utils.visualization import get_confusion_matrix\n",
    "get_confusion_matrix(gw_rf, gw_x_test, gw_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yucky.\n",
    "\n",
    "#### Q4.\n",
    "\n",
    "1. Tune the random forest.\n",
    "\n",
    "#### Neural networks\n",
    "\n",
    "We're going to go ahead and try to use a neural network classifier on this dataset. You can read about the various paramaters for a neural network classifier [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier). We're going to start off by tuning the activation function, the hidden layer sizes, and the algorithm used for backpropagation.\n",
    "\n",
    "Let's create an empty neural network model and the set of parameters we want to check out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "gw_nn = MLPClassifier()\n",
    "\n",
    "nn_params = [\n",
    "    {\n",
    "        'activation': ['relu', 'logistic'],\n",
    "        'hidden_layer_sizes': [(10), (10, 10), (10, 10, 10), (10, 10, 10, 10)],\n",
    "        'solver': ['adam', 'lbfgs']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we're ready to do our grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'activation': ['relu', 'logistic'], 'hidden_layer_sizes': [10, (10, 10), (10, 10, 10), (10, 10, 10, 10)], 'solver': ['adam', 'lbfgs']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search = GridSearchCV(gw_nn, nn_params, cv = 10)\n",
    "nn_grid_search.fit(gw_x_train, gw_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best performance was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6241610738255033"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the parameters that gave that best score were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu', 'hidden_layer_sizes': (10, 10), 'solver': 'adam'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, that's not the whole story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3\n",
    "\n",
    "* You should have some errors. What were they? What do they mean? How can we fix them?\n",
    "\n",
    "There weren't enough iterations to actually reach a convergent solution. A first idea is to increase the number of maximum iterations to see if the model will converge. When we call the `MLPClassifier`, we can set the `max_iter` value to some number that will be shared by all the models we discover during our grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_nn = MLPClassifier(max_iter = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And going back into our gridsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=5000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'activation': ['relu', 'logistic'], 'hidden_layer_sizes': [10, (10, 10), (10, 10, 10), (10, 10, 10, 10)], 'solver': ['adam', 'lbfgs']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search = GridSearchCV(gw_nn, nn_params, cv = 10)\n",
    "nn_grid_search.fit(gw_x_train, gw_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6577181208053692"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'logistic', 'hidden_layer_sizes': 10, 'solver': 'adam'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is still very bad. What else can we try?\n",
    "\n",
    "The number of iterations we're using is enough for the models to converge, so we're fairly confident that a good number of hidden layers is 1. Let's see if we can get a good improvement in performance by varying the size of a single layer. We're going to drop the `solver` and `activation` parameters for now, since they have less of an impact on model performance than the architecture of the model itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params = [\n",
    "    {\n",
    "        'hidden_layer_sizes': [tuple([10 * (i + 1)]) for i in range(20)],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=5000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,), (60,), (70,), (80,), (90,), (100,), (110,), (120,), (130,), (140,), (150,), (160,), (170,), (180,), (190,), (200,)]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gw_nn = MLPClassifier(max_iter = 5000)\n",
    "nn_grid_search = GridSearchCV(gw_nn, nn_params, cv = 10)\n",
    "nn_grid_search.fit(gw_x_train, gw_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6644295302013423"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': (50,)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still yucky. We can continue on like this, constantly adjusting our hyperparameter search space to try and increase our performance. However, we should take a step back and reevaluate whether or not a neural network is the best fit for this problem.\n",
    "\n",
    "#### Q3.\n",
    "\n",
    "1. Why is the neural network not getting great results?\n",
    "2. What are some possible fixes?\n",
    "3. If you were to continue changing the hyperparameters for this neural network, what might be your next steps?\n",
    "\n",
    "#### Other models\n",
    "\n",
    "Let's look at the [`scikit-learn` algorithm cheat-sheet](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) to see what models we might check out next:\n",
    "\n",
    "![caption](https://scikit-learn.org/stable/_static/ml_map.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
